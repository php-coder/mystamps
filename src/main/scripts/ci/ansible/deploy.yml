---

- hosts: all
  gather_facts: no
  remote_user: mystamps
  vars:
    local_war_dir: "{{ playbook_dir }}/../../../../../target"
    remote_war_dir: /data/mystamps
    uptimerobot:
      monitorid: 'MyStamps'
      apikey: "{{ lookup('env', 'UPTIMEROBOT_APIKEY') }}"
  tasks:

  - name: Getting info about WAR file
    stat:
      path: "{{ local_war_dir }}/mystamps.war"
      get_attributes: no
      get_checksum: no
      get_mime: no
    register: war_file
    become: no
    delegate_to: 127.0.0.1

  - name: Ensuring that WAR file exists
    assert:
      that:
        war_file.stat.exists
      quiet: yes
    become: no
    delegate_to: 127.0.0.1

  - name: Copying a candidate WAR file
    copy:
      src: "{{ local_war_dir }}/mystamps.war"
      dest: "{{ remote_war_dir }}/mystamps-candidate.war"
      owner: mystamps
      group: mystamps
      mode: '0755'

  # The command to execute JVM is similar to ExecStart from /etc/systemd/system/mystamps.service
  - name: Ensuring whether Liquibase migrations are valid
    shell: |
      set -o nounset
      set -o errexit
      set -o pipefail
      eval "$(sed -n '/^[A-Z]/s||export &|p' mystamps.conf)"
      java $JAVA_OPTS -jar mystamps-candidate.war liquibase validate
    args:
      chdir: /data/mystamps
      executable: /bin/bash
    changed_when: False
    register: liquibase_validate

  - name: Show stdout of liquibase validate
    debug:
      var: liquibase_validate.stdout_lines
    when: not liquibase_validate.failed

  - name: Show stderr of liquibase validate
    debug:
      var: liquibase_validate.stderr_lines
    when: not liquibase_validate.failed

  - name: Stopping monitoring
    uptimerobot:
      monitorid: "{{ uptimerobot.monitorid }}"
      apikey: "{{ uptimerobot.apikey }}"
      state: paused
    retries: 5
    delay: 1
    ignore_errors: yes
    when: uptimerobot is defined and uptimerobot.monitorid and uptimerobot.apikey

  # we can't use systemd module here because our sudoers allows to execute only exact commands
  - name: Stopping service # noqa 301 ignoring this because we're always stopping service before deploy
    raw:
      sudo systemctl stop mystamps

  - name: Copying WAR file
    copy:
      src: "{{ remote_war_dir }}/mystamps-candidate.war"
      dest: "{{ remote_war_dir }}/mystamps.war"
      remote_src: yes
      owner: mystamps
      group: mystamps
      mode: '0755'
      backup: yes

  # we can't use systemd module here because our sudoers allows to execute only exact commands
  - name: Starting service # noqa 301 ignoring this because we're always starting service after deploy
    raw:
      sudo systemctl start mystamps

  - name: Starting monitoring
    uptimerobot:
      monitorid: "{{ uptimerobot.monitorid }}"
      apikey: "{{ uptimerobot.apikey }}"
      state: started
    retries: 5
    delay: 1
    ignore_errors: yes
    when: uptimerobot is defined and uptimerobot.monitorid and uptimerobot.apikey

